# HumanOrAIAnalyzer
## Classification of Human-Written and AI-Generated Essays using Bidirectional LSTM
The project focuses on classifying essays into two categories: those written by students and those generated by large language models (LLMs), with the aim of contributing to Natural Language Processing (NLP) advancements in Educational Technology.

Key Components:
1. **Dataset Overview:** The original dataset comprises 10,000 essays from various sources, divided into training and test sets. These essays respond to different prompts, with some written by students and others generated by LLMs.
2. **Enhanced Dataset:** The updated dataset, comprising 520,151 essays, is meticulously augmented from various Kaggle sources. It aims to prevent information leakage and offers a diverse collection for model training.
3. **Data Processing:** The preprocessing involves converting text to lowercase, removing punctuations, and tokenizing. Feature engineering includes tokenization, sequence padding for LSTM, and training Word2Vec models for word embeddings.
4. **Model Training:** The Bidirectional LSTM model architecture is built and trained using the training data. Two models, FastText and Word2Vec, are evaluated for their performance.
5. **Evaluation:** Both models achieve high accuracy on the validation set but encounter challenges in generalization on the hidden testing set. The FastText model faces execution errors, while the Word2Vec model yields poor results. Future work involves addressing these issues through hyperparameter tuning, refining preprocessing techniques, augmenting training data, and conducting rigorous cross-validation.

Conclusion:
The project highlights the importance of robust model evaluation and the need to address challenges such as overfitting, data leakage, and model bias. Future efforts should focus on enhancing model generalization and reliability in real-world applications.
